import streamlit as st
import google.generativeai as genai
from PIL import Image
import json
import io
import re
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials

info = dict(st.secrets["gcp_service_account"])
info["private_key"] = info["private_key"].replace("\\n", "\n")

scope = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
creds = Credentials.from_service_account_info(info, scopes=scope)
client = gspread.authorize(creds)

SHEET_URL = st.secrets["GSHEETS_URL"]
sheet = client.open_by_url(SHEET_URL).sheet1

def get_data():
    try:
        data = sheet.get_all_records()
        return pd.DataFrame(data) if data else pd.DataFrame(columns=['username', 'usage', 'status', 'receipt_img'])
    except:
        return pd.DataFrame(columns=['username', 'usage', 'status', 'receipt_img'])

def save_data(df):
    sheet.clear()
    sheet.update([df.columns.values.tolist()] + df.values.tolist())

if 'user_info' not in st.session_state:
    st.session_state.user_info = None
if 'usage_count' not in st.session_state:
    st.session_state.usage_count = 0
if 'is_premium' not in st.session_state:
    st.session_state.is_premium = False
if 'current_df' not in st.session_state:
    st.session_state.current_df = None

if not st.session_state.user_info:
    st.set_page_config(page_title="QuickSheet AI Pro", layout="wide")
    
    st.title("ğŸš€ QuickSheet AI Pro")
    st.subheader("Ø¥ÙŠÙƒÙˆ ÙŠØ±Ø­Ø¨ Ø¨Ùƒ! Ø­ÙˆÙ„ ÙˆØµÙˆÙ„Ø§ØªÙƒ Ø§Ù„ÙˆØ±Ù‚ÙŠØ© Ø¥Ù„Ù‰ ØªÙ‚Ø§Ø±ÙŠØ± Ø°ÙƒÙŠØ© Ø¨Ø«ÙˆØ§Ù†Ù")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.info("ğŸ¯ **Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©**\nØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªØ·ÙˆØ±.")
    with col2:
        st.success("ğŸ“Š **ØªØ­Ù„ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ**\nAuto Insights ØªØ´Ø±Ø­ Ù„Ùƒ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙÙˆØ±Ø§Ù‹.")
    with col3:
        st.warning("ğŸ’¬ **Ø¯Ø±Ø¯Ø´Ø© Ø°ÙƒÙŠØ©**\nØªØ­Ø¯Ø« Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ ÙˆØ§Ø·Ù„Ø¨ Ù…Ù†Ù‡Ø§ Ù…Ø§ ØªØ´Ø§Ø¡.")

    st.divider()
    
    st.write("### ğŸ’³ Ø§Ø®ØªØ± Ø®Ø·ØªÙƒ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©")
    p_col1, p_col2 = st.columns(2)
    with p_col1:
        st.markdown("""
        **Ø§Ù„Ø®Ø·Ø© Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ© (Free)**
        - 10 Ù…Ø­Ø§ÙˆÙ„Ø§Øª ØªØ­Ù„ÙŠÙ„.
        - Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©.
        - Ø¯Ø¹Ù… ÙÙ†ÙŠ Ù…Ø­Ø¯ÙˆØ¯.
        - **Ø§Ù„Ø³Ø¹Ø±: 0$**
        """)
    with p_col2:
        st.markdown("""
        **Ø®Ø·Ø© Ø§Ù„Ù…Ø­ØªØ±ÙÙŠÙ† (VIP) ğŸ’**
        - Ù…Ø­Ø§ÙˆÙ„Ø§Øª ØºÙŠØ± Ù…Ø­Ø¯ÙˆØ¯Ø©.
        - Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© (Smart Merge).
        - ØªØ­Ù„ÙŠÙ„ Auto Insights Ù…ØªÙ‚Ø¯Ù….
        - **Ø§Ù„Ø³Ø¹Ø±: 25$ / Ø´Ù‡Ø±ÙŠØ§Ù‹**
        """)
    
    st.divider()
    
    st.write("### ğŸ”‘ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„Ù„Ø¨Ø¯Ø¡")
    name = st.text_input("Ø£Ø¯Ø®Ù„ Ø§Ø³Ù…Ùƒ Ø£Ùˆ Ø¨Ø±ÙŠØ¯Ùƒ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ:")
    if st.button("Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§Ù… ğŸš€"):
        if name:
            df = get_data()
            user_row = df[df['username'] == name]
            if user_row.empty:
                sheet.append_row([name, 0, "Free", ""])
                st.session_state.user_info = {"name": name}
                st.session_state.usage_count = 0
                st.session_state.is_premium = False
            else:
                user_dict = user_row.iloc[0].to_dict()
                st.session_state.user_info = {"name": user_dict['username']}
                st.session_state.usage_count = int(user_dict['usage'])
                st.session_state.is_premium = (user_dict['status'] == "VIP")
            st.rerun()
else:
    st.sidebar.write(f"Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙŠØ§ Ø¨Ø·Ù„ØŒ {st.session_state.user_info['name']}")
    status = "ğŸ’ VIP Premium" if st.session_state.is_premium else "ğŸ†“ Free"
    st.sidebar.markdown(f"Ø§Ù„Ø­Ø§Ù„Ø©: {status}")
    
    if st.sidebar.button("ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬"):
        st.session_state.user_info = None
        st.session_state.current_df = None
        st.rerun()
        
    if not st.session_state.is_premium:
        st.sidebar.write(f"Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: {st.session_state.usage_count}/10")
        st.sidebar.markdown("---")
        st.sidebar.subheader("ØªØ±Ù‚ÙŠØ© Ø¥Ù„Ù‰ VIP ğŸš€")
        st.sidebar.write("Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ: $25 / Ø´Ù‡Ø±ÙŠØ§Ù‹")
        st.sidebar.write("Ø­ÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ù‚Ù… Ø§Ù„ÙƒÙŠ ÙƒØ§Ø±Ø¯:")
        st.sidebar.code("7280146585")
        receipt = st.sidebar.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„", type=['png', 'jpg', 'jpeg'])
        if st.sidebar.button("ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø¯ÙØ¹ âœ…"):
            if receipt:
                st.sidebar.success("ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¥ÙŠØµØ§Ù„! Ø³ÙŠØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù€ VIP Ù‚Ø±ÙŠØ¨Ø§Ù‹.")
                df = get_data()
                df.loc[df['username'] == st.session_state.user_info['name'], 'receipt_img'] = "Pending Verification"
                save_data(df)
            else:
                st.sidebar.error("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ø§Ù„Ø¥ÙŠØµØ§Ù„ Ø£ÙˆÙ„Ø§Ù‹.")

    st.title("ğŸ“Š Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… QuickSheet")
    
    if not st.session_state.is_premium and st.session_state.usage_count >= 10:
        st.error("Ø§Ù†ØªÙ‡Øª Ø§Ù„ÙØªØ±Ø© Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ±Ù‚ÙŠØ© Ù„Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±.")
        uploaded_files = None
    else:
        uploaded_files = st.file_uploader("Ø§Ø±ÙØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø£Ùˆ Ø§Ù„ØµÙˆØ±", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)

    if uploaded_files:
        user_note = st.text_input("Ø£Ø¶Ù Ù…Ù„Ø§Ø­Ø¸Ø© Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
        if st.button("Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ğŸš€"):
            with st.spinner('Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„...'):
                try:
                    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
                    model = genai.GenerativeModel('gemini-2.0-flash')
                    should_merge = any(word in user_note.lower() for word in ["Ø§Ø¬Ù…Ø¹", "Ø¯Ù…Ø¬", "merge", "combine", "ÙˆØ§Ø­Ø¯", "ÙˆØ­Ø¯Ù‡"])
                    
                    detailed_prompt = f"""
                    Act as a professional data entry expert. Extract ALL information from the image(s).
                    1. Identify headers, rows, and labels.
                    2. Structure as a flat JSON list of objects [].
                    3. Include all metadata in every row object.
                    4. Use the exact labels found in the image.
                    5. If multiple images, combine rows into one continuous list.
                    Special Note: {user_note} 
                    Return ONLY raw JSON.
                    """

                    if should_merge:
                        images = [Image.open(f) for f in uploaded_files]
                        response = model.generate_content([detailed_prompt, *images])
                        clean_json = re.search(r'\[.*\]', response.text, re.DOTALL)
                        if clean_json:
                            data = json.loads(clean_json.group())
                            if data: st.session_state.current_df = pd.DataFrame(data)
                    else:
                        all_data = []
                        for uploaded_file in uploaded_files:
                            img = Image.open(uploaded_file)
                            response = model.generate_content([detailed_prompt, img])
                            clean_json = re.search(r'\[.*\]', response.text, re.DOTALL)
                            if clean_json:
                                data = json.loads(clean_json.group())
                                if data: all_data.extend(data)
                        if all_data: st.session_state.current_df = pd.DataFrame(all_data)

                    if st.session_state.current_df is not None:
                        if not st.session_state.is_premium:
                            st.session_state.usage_count += len(uploaded_files)
                            df_db = get_data()
                            df_db.loc[df_db['username'] == st.session_state.user_info['name'], 'usage'] = st.session_state.usage_count
                            save_data(df_db)
                        st.success("ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
                except Exception as e:
                    st.error(f"Error: {e}")

    if st.session_state.current_df is not None:
        st.divider()
        st.subheader("ğŸ’¡ ØªØ­Ù„ÙŠÙ„Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ© (Auto Insights)")
        with st.expander("Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", expanded=True):
            try:
                insight_model = genai.GenerativeModel('gemini-2.0-flash')
                insight_prompt = f"""
                As an Iraqi Business Assistant named Echo, provide a 3-bullet point summary of this data in polite Iraqi dialect.
                Data: {st.session_state.current_df.to_string()}
                Focus on: Total sum, highest value, and patterns. Be encouraging.
                """
                insight_res = insight_model.generate_content(insight_prompt)
                st.info(insight_res.text)
            except:
                st.write("Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ ØºÙŠØ± Ù…ØªÙˆÙØ± Ø­Ø§Ù„ÙŠØ§Ù‹.")

        st.subheader("ğŸ’¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©")
        st.dataframe(st.session_state.current_df, use_container_width=True)
        
        chat_input = st.chat_input("Ø§Ø·Ù„Ø¨ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙˆÙ„ (Ù…Ø«Ù„Ø§Ù‹: Ø±ØªØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø³Ø¹Ø±)")
        if chat_input:
            with st.spinner('Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„...'):
                try:
                    chat_model = genai.GenerativeModel('gemini-2.0-flash')
                    chat_prompt = f"""
                    Update the pandas DataFrame 'df' based on: {chat_input}.
                    Columns: {list(st.session_state.current_df.columns)}.
                    STRICT: Use pd.to_numeric for math. Append ONE total row if asked for sum.
                    Return ONLY valid python code starting with 'df = '.
                    """
                    chat_res = chat_model.generate_content(chat_prompt)
                    clean_code = chat_res.text.replace('```python', '').replace('```', '').strip()
                    ldict = {'df': st.session_state.current_df.copy(), 'pd': pd}
                    exec(clean_code, globals(), ldict)
                    st.session_state.current_df = ldict['df']
                    st.rerun()
                except Exception as e:
                    st.error(f"Ø®Ø·Ø£: ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯. {e}")

        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            st.session_state.current_df.to_excel(writer, index=False, sheet_name="Sheet1")
            ws = writer.sheets["Sheet1"]
            for idx, col in enumerate(st.session_state.current_df.columns):
                max_len = max(st.session_state.current_df[col].astype(str).map(len).max(), len(str(col))) + 2
                ws.column_dimensions[chr(65 + idx)].width = max_len
        
        st.download_button("ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø¥ÙƒØ³ÙŠÙ„ ğŸ“¥", buffer.getvalue(), "QuickSheet_Analysis.xlsx")
